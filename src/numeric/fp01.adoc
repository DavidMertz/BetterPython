== Comparing NaNs (And Other Floating Point Numbers)

The IEEE-754-1985 standard for floating point numbers includes a special kind
of value called "Not a Number" (NaN).footnote:[See discussion at
https://en.wikipedia.org/wiki/IEEE_754-1985 for more information.
Unfortunately, these standards themselves are not available free of charge,
but their technical requirements are widely published in other forms.
Technically, this standard was superseded by IEEE-754-2008, and then by
IEEE-754-2019, but nothing relevant herein was modified.]  Nearly all
programming languages and computer architectures implement IEEE-754 and NaN
values.  As well as being perfectly good floating point values in plain
Python, NaNs serve special roles when they are individual values within NumPy
arrays or Pandas DataFrames (and Xarray DataArrays, and Vaex DataFrames, and
in other numeric special collections).

[NOTE]
.Getting pedantic about NaNs
====
To be precise about things, a NaN is not _a value_ but rather a family of
values marked by a particular bit pattern.  There are 16,777,214 32-bit NaNs,
and 9,007,199,254,740,990 64-bit NaNs.  Moreover, within this vast space of
possible NaNs, the bit patterns are split evenly between _signaling_ and
_quiet_ NaNs.

This is a lot of complication that the original designers of IEEE-754,
including main architect William Kahan, hoped would be utilized to carry
_payloads_ describing the circumstances within a computation where a
non-representable floating point value arose.  As things panned out, no widely
used computing system makes any use of the many NaN values, and all basically
treat every NaN as the same value.
====

Let's dig a bit deeper into the weeds before showing the mistake of this
section.  These details apply to many concerns.  A floating point number is
represented as a sign bit, followed by an exponent, followed by a
mantissa.footnote:[To get even more technical, an alternate representation
exists for _subnormal numbers_
(https://en.wikipedia.org/wiki/Subnormal_number) where we want to represent
floating point numbers close to zero with greater precision]  A NaN is simply
a number that has all of its exponent bits set to 1s.  Whatever happens to
occur in the mantissa, it remains a NaN and is treated in the same special
manner.  Let's see this in action:

.Looking at bit patterns of floating point numbers
[source,python]
----
>>> import struct, math
>>> def show32(num):                               # (1)
...     pack32 = struct.pack("!f", num)
...     bits = ''.join(f"{c:0>8b}" for c in pack32)
...     sign = bits[0]
...     exp = bits[1:9]
...     mantissa = bits[9:]
...     print("- exponent mantissa")
...     print(f"{sign} {exp} {mantissa}")
...
>>> show32(3.1415)
- exponent mantissa
0 10000000 10010010000111001010110
>>> show32(-math.pi)
- exponent mantissa
1 10000000 10010010000111111011011
----

(1) We "cast" a floating point to 32-bit, even if its native format is wider.

We can see that a very rough approximation of Ï€ has the same exponent and most
of the same mantissa bits as the best approximation we can make of negative pi
within IEEE-754.  The sign bit is flipped between the two numbers spelled out
as bits.  But what about operations that result in NaNs?

.Looking at NaN bit patterns generated by Python
[source,python]
----
>>> show32(math.nan)
- exponent mantissa
0 11111111 10000000000000000000000
>>> show32(math.inf/math.inf)
- exponent mantissa
1 11111111 10000000000000000000000
>>> show32(-math.nan)
- exponent mantissa
1 11111111 10000000000000000000000
>>> show32(1e500-1e500)
- exponent mantissa
1 11111111 10000000000000000000000
>>> show32(0 * math.inf)
- exponent mantissa
1 11111111 10000000000000000000000
----

Python, like almost all other programming languages, simply uses one of the
millions (or quadrillions) of possible NaNs, regardless of how we arrived at
it.  The leading `1` in the mantissa technically makes it a signaling NaN, but
no Python library I know of pays any attention to this fact.  It's technically
possible in Python to construct a NaN with a different bit pattern, but it
requires arcana from the `struct` or `ctypes` modules; no "normal Python"
operation will do this, nor pay any attention to the special value if you do
so.

Let's try a comparison that at first, certainly, _seems like_ it should
succeed:

.Comparing floating point numbers, including NaNs
[source,python]
----
>>> a = [math.pi, math.e, float('nan'), math.tau]
>>> b = [math.pi, math.e, math.nan, math.tau]
>>> a == b
False
----

The bit pattern stored for the NaNs in `a` and `b` are, in fact, identical.
Likewise for the other mentioned mathematical constants.  The problem is that
according to IEEE-754, no NaN will ever compare as equal to another, even if
their payloads are identical.

[source,python]
----
>>> math.nan == math.nan, math.nan is math.nan
(False, True)
>>> math.isnan(math.nan)                           # (1)
True
----

(1) The cleanest way to check whether a value is NaN.

A NaN is a peculiar Python object that can be self-identical, yet unequal to
itself.  Moreover, the example shown allows us to fix another common problem
with floating point numbers that other sections will also address.  While the
examples for `a` and `b` _do_ produce bit-wise identical values for the non-NaN
constants, in general, "mathematically" equal numbers that we arrive at by
different sequences of floating point operations will more-often-than-not be
unequal because of rounding issues.  A robust way to compare two iterables of
floating point numbers is shown.

.Robustly comparing floating point numbers with NaN equivalence
[source,python]
----
>>> def approxEqualNums(seq1, seq2):
...     for x, y in zip(seq1, seq2, strict=True):
...         if math.isnan(x) and math.isnan(y):
...             continue
...         elif math.isclose(x, y):               # (1)
...             continue
...         else:
...             return False
...     return True
...
>>> approxEqualNums(a, b)
True
----

(1) The function `math.isclose()` has `rel_tol` and `abs_tol` optional
arguments to fine-tune what "closeness" means.  See the Python documentation
for details.

The function `approxEqualNums()` will raise a `ValueError` if the iterables
passed to it are of different lengths, but will raise a `TypeError` if some of
the elements are non-numeric.  The function is not restricted to lists, but
will work on anything for which `isinstance(o, collections.abc.Iterable)`
holds.  In practice, you usually want something that is specifically a
`collections.abc.Sequence` since unordered collections may accidentally produce
either `True` or `False` answers.  For example:

[source,python]
----
>>> approxEqualNums((1, 2, 3), {1:None, 2:None, 3:None})
True
>>> approxEqualNums((1, 2, 3), {1, 2, 3})          # (1)
True
>>> approxEqualNums((3, 2, 1), {3, 2, 1})          # (2)
False
>>> approxEqualNums([0, 1, 2, 3], range(4))
True
----

(1) Do not rely on the ordering of sets, even though this example is
coincidentally order-preserving.  Dicts preserve insertion-order.

(2) An example where sets do not preserve their "order" during iteration.


